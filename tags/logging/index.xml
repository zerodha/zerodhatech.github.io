<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>logging on Zerodha Tech Blog</title><link>https://zerodha.tech/tags/logging/</link><description>Recent content in logging on Zerodha Tech Blog</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 23 Mar 2023 00:00:00 +0530</lastBuildDate><atom:link href="https://zerodha.tech/tags/logging/index.xml" rel="self" type="application/rss+xml"/><item><title>Logging at Zerodha</title><link>https://zerodha.tech/blog/logging-at-zerodha/</link><pubDate>Thu, 23 Mar 2023 00:00:00 +0530</pubDate><guid>https://zerodha.tech/blog/logging-at-zerodha/</guid><description>At Zerodha, we run a multitude of internal and public-facing services that generate copious amounts of logs. While developers use these logs to debug or troubleshoot incidents, some services also emit logs that must be persisted for prolonged periods to comply with numerous regulatory requirements. In this post, I will delve into our experiences with the ELK stack, why it didn&amp;rsquo;t fit our needs and our migration to ClickHouse.
Why ELK wasnâ€™t the right fit for us In 2018, we adopted the ELK stack as our de facto stack for storing application logs.</description></item></channel></rss>